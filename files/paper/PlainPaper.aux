\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{shkurti2012multi}
\citation{whitcomb2000advances}
\citation{bingham2010robotic}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\citation{krizhevsky2012imagenet}
\citation{zhang2016colorful}
\citation{zhu2017unpaired}
\citation{zhang2016colorful}
\citation{iizuka2016let}
\citation{jordt2014underwater}
\citation{torres2005color}
\citation{li2017watergan}
\citation{pathak2016context}
\citation{Gatys_2016_CVPR}
\citation{isola2016image}
\citation{zhu2017unpaired}
\citation{isola2016image}
\newlabel{fig:samples}{{1}{2}{Introduction}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Sample underwater images with natural and man-made artifacts (which in this case is our underwater robot) displaying the diversity of distortions that can occur. With the varying camera-to-object distances in the images, the distortion and loss of color varies between the different images.}}{2}{figure.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}}
\newlabel{sec:related}{{2}{2}{Related Work}{section.2}{}}
\citation{goodfellow2014generative}
\citation{arjovsky2017towards}
\citation{lecun2010mnist}
\citation{mao2016least}
\citation{arjovsky2017wasserstein}
\citation{gulrajani2017improved}
\citation{zhao2016energy}
\citation{arjovsky2017wasserstein}
\citation{villani2008optimal}
\citation{gulrajani2017improved}
\citation{arjovsky2017wasserstein}
\citation{gulrajani2017improved}
\@writefile{toc}{\contentsline {section}{\numberline {3}Methodology}{3}{section.3}}
\newlabel{sec:methodology}{{3}{3}{Methodology}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Dataset Generation}{3}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Paired samples of ground truth and distorted images generated by CycleGAN. Top row: Ground truth. Bottom row: Generated samples.}}{3}{figure.2}}
\newlabel{fig:cgan_samples}{{2}{3}{Paired samples of ground truth and distorted images generated by CycleGAN. Top row: Ground truth. Bottom row: Generated samples}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Adversarial Networks}{3}{subsection.3.2}}
\newlabel{sec:gans}{{3.2}{3}{Adversarial Networks}{subsection.3.2}{}}
\citation{mathieu2015deep}
\citation{isola2016image}
\citation{ronneberger2015u}
\citation{pmlr-v37-ioffe15}
\citation{nair2010rectified}
\citation{ulyanov2016instance}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Image Gradient Difference Loss}{4}{subsection.3.3}}
\newlabel{gdl_eq}{{5}{4}{Image Gradient Difference Loss}{equation.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Network Architecture and Training Details}{4}{subsection.3.4}}
\citation{radford2015unsupervised}
\citation{gulrajani2017improved}
\citation{ba2016layer}
\citation{isola2016image}
\citation{li2016precomputed}
\citation{deng2009imagenet}
\citation{canny1986computational}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{5}{section.4}}
\newlabel{sec:experiments}{{4}{5}{Experiments}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Datasets}{5}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Evaluation}{5}{subsection.4.2}}
\citation{canny1986computational}
\citation{mathieu2015deep}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Samples from our ImageNet testing set. The network can both recover color and also correct color if a small amount is present.}}{6}{figure.3}}
\newlabel{fig:test_samples}{{3}{6}{Samples from our ImageNet testing set. The network can both recover color and also correct color if a small amount is present}{figure.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Comparison to CycleGAN}{6}{subsection.4.3}}
\citation{islam2017mixed}
\citation{shkurti2017underwater}
\citation{islam2017mixed}
\citation{islam2017mixed}
\citation{kingma2014adam}
\citation{abadi2016tensorflow}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Distances in image space}}{7}{table.1}}
\newlabel{tab:one}{{1}{7}{Distances in image space}{table.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Gradient Difference Loss Metrics}}{7}{table.2}}
\newlabel{fig:gdl_tbl}{{2}{7}{Gradient Difference Loss Metrics}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Diver Tracking using Frequency-Domain Detection}{7}{subsection.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \relax \fontsize  {10}{12}\selectfont  \abovedisplayskip 10\p@ plus2\p@ minus5\p@ \abovedisplayshortskip \z@ plus3\p@ \belowdisplayshortskip 6\p@ plus3\p@ minus3\p@ \def \leftmargin \leftmargini \topsep 4\p@ plus2\p@ minus2\p@ \parsep 2\p@ plus\p@ minus\p@ \itemsep \parsep {\leftmargin \leftmargini \topsep 6\p@ plus2\p@ minus2\p@ \parsep 3\p@ plus2\p@ minus\p@ \itemsep \parsep }\belowdisplayskip \abovedisplayskip {Running the Canny Edge Detector on sample images. Both variants of UGAN contain less noise than CycleGAN, and are closer in the image space to the original. For each pair, the top row is the input image, and bottom row the result of the edge detector. The figure depicts four different sets of images, successively labeled A to D from top to bottom. See Table\nobreakspace  {}\ref  {tab:one}.}}}{7}{figure.4}}
\newlabel{fig:canny_samples}{{4}{7}{\small {Running the Canny Edge Detector on sample images. Both variants of UGAN contain less noise than CycleGAN, and are closer in the image space to the original. For each pair, the top row is the input image, and bottom row the result of the edge detector. The figure depicts four different sets of images, successively labeled A to D from top to bottom. See Table~\ref {tab:one}.}}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Training and Inference Performance}{7}{subsection.4.5}}
\bibdata{cambibs}
\bibcite{abadi2016tensorflow}{1}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Local image patches extracted for quantitative comparisons, shown in Tables\nobreakspace  {}\ref  {fig:gdl_tbl} and\nobreakspace  {}\ref  {fig:mean_tbl}. Each patch was resized to $64 \times 64$, but shown enlarged for viewing ability.}}{8}{figure.5}}
\newlabel{fig:zoom}{{5}{8}{Local image patches extracted for quantitative comparisons, shown in Tables~\ref {fig:gdl_tbl} and~\ref {fig:mean_tbl}. Each patch was resized to $64 \times 64$, but shown enlarged for viewing ability}{figure.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{8}{section.5}}
\newlabel{fig:mdpm}{{4.4}{9}{Diver Tracking using Frequency-Domain Detection}{subsection.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Performance of MDPM tracker \cite  {islam2017mixed} on both real (top row) and generated (second row) images; the Table compares the detection performance for both sets of images over a sequence of $500$ frames. }}{9}{figure.6}}
\newlabel{mdpmStuff}{{6}{9}{Performance of MDPM tracker \cite {islam2017mixed} on both real (top row) and generated (second row) images; the Table compares the detection performance for both sets of images over a sequence of $500$ frames}{figure.6}{}}
\bibcite{arjovsky2017towards}{2}
\bibcite{arjovsky2017wasserstein}{3}
\bibcite{ba2016layer}{4}
\bibcite{bingham2010robotic}{5}
\bibcite{canny1986computational}{6}
\bibcite{deng2009imagenet}{7}
\bibcite{Gatys_2016_CVPR}{8}
\bibcite{goodfellow2014generative}{9}
\bibcite{gulrajani2017improved}{10}
\bibcite{iizuka2016let}{11}
\bibcite{pmlr-v37-ioffe15}{12}
\bibcite{islam2017mixed}{13}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Mean and Standard Deviation Metrics}}{10}{table.3}}
\newlabel{fig:mean_tbl}{{3}{10}{Mean and Standard Deviation Metrics}{table.3}{}}
\bibcite{isola2016image}{14}
\bibcite{jordt2014underwater}{15}
\bibcite{kingma2014adam}{16}
\bibcite{krizhevsky2012imagenet}{17}
\bibcite{lecun2010mnist}{18}
\bibcite{li2016precomputed}{19}
\bibcite{li2017watergan}{20}
\bibcite{mao2016least}{21}
\bibcite{mathieu2015deep}{22}
\bibcite{nair2010rectified}{23}
\bibcite{pathak2016context}{24}
\bibcite{radford2015unsupervised}{25}
\bibcite{ronneberger2015u}{26}
\bibcite{shkurti2017underwater}{27}
\bibcite{shkurti2012multi}{28}
\bibcite{torres2005color}{29}
\bibcite{ulyanov2016instance}{30}
\bibcite{villani2008optimal}{31}
\bibcite{whitcomb2000advances}{32}
\bibcite{zhang2016colorful}{33}
\bibcite{zhao2016energy}{34}
\bibcite{zhu2017unpaired}{35}
\bibstyle{plain}
