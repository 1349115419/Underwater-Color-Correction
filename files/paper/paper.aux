\relax 
\citation{shkurti2012multi}
\citation{whitcomb2000advances}
\citation{zhu2017unpaired}
\citation{zhang2016colorful}
\citation{iizuka2016let}
\citation{torres2005color}
\citation{li2017watergan}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Sample underwater images displaying the diversity of distortion that can occur. \textbf  {Maybe say something about how some images lost all color, but some kept some color for close objects.}}}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{1}}
\citation{pathak2016context}
\citation{Gatys_2016_CVPR}
\citation{isola2016image}
\citation{zhu2017unpaired}
\citation{isola2016image}
\citation{zhu2017unpaired}
\citation{goodfellow2014generative}
\citation{mao2016least}
\citation{arjovsky2017wasserstein}
\citation{gulrajani2017improved}
\citation{zhao2016energy}
\citation{arjovsky2017wasserstein}
\citation{villani2008optimal}
\citation{gulrajani2017improved}
\citation{arjovsky2017wasserstein}
\citation{gulrajani2017improved}
\citation{mathieu2015deep}
\@writefile{toc}{\contentsline {section}{\numberline {III}Method}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Dataset Generation}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-B}}Adversarial Networks}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Paired samples of ground truth and distorted images generated by CycleGAN. Top row: Ground truth. Bottom row: Generated samples.}}{2}}
\citation{isola2016image}
\citation{ronneberger2015u}
\citation{pmlr-v37-ioffe15}
\citation{nair2010rectified}
\citation{radford2015unsupervised}
\citation{gulrajani2017improved}
\citation{ba2016layer}
\citation{kingma2014adam}
\citation{abadi2016tensorflow}
\citation{deng2009imagenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-C}}Image Gradient Difference Loss}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-D}}Network Architecture and Training Details}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiments}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Datasets}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Evaluation}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Comparison to CycleGAN}{3}}
\bibdata{cambibs}
\bibcite{shkurti2012multi}{1}
\bibcite{whitcomb2000advances}{2}
\bibcite{zhu2017unpaired}{3}
\bibcite{zhang2016colorful}{4}
\bibcite{iizuka2016let}{5}
\bibcite{torres2005color}{6}
\bibcite{li2017watergan}{7}
\bibcite{pathak2016context}{8}
\bibcite{Gatys_2016_CVPR}{9}
\bibcite{isola2016image}{10}
\bibcite{goodfellow2014generative}{11}
\bibcite{mao2016least}{12}
\bibcite{arjovsky2017wasserstein}{13}
\bibcite{gulrajani2017improved}{14}
\bibcite{zhao2016energy}{15}
\bibcite{villani2008optimal}{16}
\bibcite{mathieu2015deep}{17}
\bibcite{ronneberger2015u}{18}
\bibcite{nair2010rectified}{19}
\bibcite{radford2015unsupervised}{20}
\bibcite{pmlr-v37-ioffe15}{21}
\bibcite{ba2016layer}{22}
\bibcite{kingma2014adam}{23}
\bibcite{abadi2016tensorflow}{24}
\bibcite{deng2009imagenet}{25}
\bibstyle{ieeetr}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}}Diver Tracking}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{4}}
\@writefile{toc}{\contentsline {section}{References}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Zooming in on comparisons.}}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Running the Canny Edge Detector on sample images. Both variants of UGAN contain less noise than CycleGAN, and are closer in the image space to the original. For each pair, the top row is the input image, and bottom row the result of the edge detector.}}{5}}
