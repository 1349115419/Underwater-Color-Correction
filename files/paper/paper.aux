\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{shkurti2012multi}
\citation{whitcomb2000advances}
\citation{krizhevsky2012imagenet}
\citation{zhang2016colorful}
\citation{zhu2017unpaired}
\providecommand \oddpage@label [2]{}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\newlabel{fig:samples}{{I}{1}{Introduction}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Sample underwater images displaying the diversity of distortion that can occur. \textbf  {Maybe say something about how some images lost all color, but some kept some color for close objects.}}}{1}{figure.1}}
\citation{zhang2016colorful}
\citation{iizuka2016let}
\citation{torres2005color}
\citation{li2017watergan}
\citation{pathak2016context}
\citation{Gatys_2016_CVPR}
\citation{isola2016image}
\citation{zhu2017unpaired}
\citation{isola2016image}
\citation{zhu2017unpaired}
\citation{goodfellow2014generative}
\citation{mao2016least}
\citation{arjovsky2017wasserstein}
\citation{gulrajani2017improved}
\citation{zhao2016energy}
\citation{arjovsky2017wasserstein}
\citation{villani2008optimal}
\citation{gulrajani2017improved}
\citation{arjovsky2017wasserstein}
\citation{gulrajani2017improved}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work}{2}{section.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Paired samples of ground truth and distorted images generated by CycleGAN. Top row: Ground truth. Bottom row: Generated samples.}}{2}{figure.2}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Method}{2}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-A}Dataset Generation}{2}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-B}Adversarial Networks}{2}{subsection.3.2}}
\citation{mathieu2015deep}
\citation{isola2016image}
\citation{ronneberger2015u}
\citation{pmlr-v37-ioffe15}
\citation{nair2010rectified}
\citation{radford2015unsupervised}
\citation{gulrajani2017improved}
\citation{ba2016layer}
\citation{ulyanov2016instance}
\citation{kingma2014adam}
\citation{abadi2016tensorflow}
\citation{deng2009imagenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-C}Image Gradient Difference Loss}{3}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {III-D}Network Architecture and Training Details}{3}{subsection.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiments}{3}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-A}Datasets}{3}{subsection.4.1}}
\citation{canny1986computational}
\citation{canny1986computational}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-B}Evaluation}{4}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-C}Comparison to CycleGAN}{4}{subsection.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Samples from our Imagenet testing set. The network can both recover color and also correct color if a small amount is present.}}{4}{figure.3}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Distances in image space}}{4}{table.1}}
\citation{islam2017mixed}
\citation{shkurti2017underwater}
\citation{islam2017mixed}
\citation{islam2017mixed}
\bibdata{cambibs}
\bibcite{shkurti2012multi}{1}
\bibcite{whitcomb2000advances}{2}
\bibcite{krizhevsky2012imagenet}{3}
\bibcite{zhu2017unpaired}{4}
\bibcite{zhang2016colorful}{5}
\bibcite{iizuka2016let}{6}
\bibcite{torres2005color}{7}
\bibcite{li2017watergan}{8}
\bibcite{pathak2016context}{9}
\bibcite{Gatys_2016_CVPR}{10}
\bibcite{isola2016image}{11}
\bibcite{goodfellow2014generative}{12}
\bibcite{mao2016least}{13}
\bibcite{arjovsky2017wasserstein}{14}
\bibcite{gulrajani2017improved}{15}
\bibcite{zhao2016energy}{16}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Running the Canny Edge Detector on sample images. Both variants of UGAN contain less noise than CycleGAN, and are closer in the image space to the original. For each pair, the top row is the input image, and bottom row the result of the edge detector.}}{5}{figure.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {IV-D}Diver Tracking using Frequency-Domain Detection}{5}{subsection.4.4}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Conclusion}{5}{section.5}}
\@writefile{toc}{\contentsline {section}{References}{5}{section*.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Zooming in on comparisons.}}{6}{figure.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Performance of MDPM tracker \cite  {islam2017mixed} on both real (top row) and generated (second row) images; the Table compares the detection performance for both sets of images over a sequence of $500$ frames. }}{6}{figure.6}}
\newlabel{mdpmStuff}{{6}{6}{Performance of MDPM tracker \cite {islam2017mixed} on both real (top row) and generated (second row) images; the Table compares the detection performance for both sets of images over a sequence of $500$ frames}{figure.6}{}}
\bibcite{villani2008optimal}{17}
\bibcite{mathieu2015deep}{18}
\bibcite{ronneberger2015u}{19}
\bibcite{pmlr-v37-ioffe15}{20}
\bibcite{nair2010rectified}{21}
\bibcite{radford2015unsupervised}{22}
\bibcite{ba2016layer}{23}
\bibcite{ulyanov2016instance}{24}
\bibcite{kingma2014adam}{25}
\bibcite{abadi2016tensorflow}{26}
\bibcite{deng2009imagenet}{27}
\bibcite{canny1986computational}{28}
\bibcite{islam2017mixed}{29}
\bibcite{shkurti2017underwater}{30}
\bibstyle{ieeetr}
