\section{Conclusion}
This paper presents an approach for enhancing underwater color images through the use of generative adversarial networks. We 
demonstrate the use of CycleGAN to generate dataset of paired images to provide a training set for the proposed restoration 
model. Quantitative and qualitative results demonstrate the effectiveness of this method, and using a diver tracking algorithm on 
corrected images of scuba divers show higher accuracy compared to the uncorrected image sequence.

Future work will focus on creating a larger and more diverse dataset from underwater objects, thus making the network more 
generalizable. Augmenting the data generated by CycleGAN with noise such as particle and lighting effects would improve 
the diversity of the dataset. We also intend to investigate a number of different quantitative performance metrics to evaluate 
our method.

\section*{Acknowledgment}
The authors are grateful to Oliver Hennigh for his implementation of the Gradient Difference Loss measure.